{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8240396f",
   "metadata": {},
   "source": [
    "# Kielipankki's introduction to data analysis\n",
    "\n",
    "This Notebook will follow up on the previous one about parsing VRT, so we will go through that part without comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060036af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These import statements bring in modules that we're going to use\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# This is a special directive to make plots show up in the Notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "from course_utils import VrtReader, data_dir, month_range\n",
    "# Some helpers for the course environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a different file, change the name here!\n",
    "vrt_filename = \"eduskunta-v1.5-vrt/eduskunta.vrt\"\n",
    "vrt = VrtReader(data_dir + vrt_filename, max_texts = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee3621",
   "metadata": {},
   "source": [
    "Let's try to make a basic plot showing the number of texts per time period. To do that, we need a list of time segments to serve as our X-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aaf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [text.date for text in vrt.texts]\n",
    "min_date = min(dates)\n",
    "max_date = max(dates)\n",
    "# This will be the X-axis of our graph, a list of dates of the first of every month.\n",
    "# month_range is a little custom function, you may want to use a more serious framework like Pandas for real work\n",
    "daterange = month_range(min_date, max_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b176c",
   "metadata": {},
   "source": [
    "Then for each text in `texts` we'll assign it to a bin and increment the count of that bin. We'll do this by calculating how many months after the first element of `daterange` it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f681a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little helper function: the months since year 0 of a date\n",
    "def month_number(date): return 12*date.year + date.month\n",
    "\n",
    "# Subtract this from every date\n",
    "min_months = month_number(daterange[0])\n",
    "\n",
    "# First we have zero texts in every bin\n",
    "counts = [0 for date in daterange]\n",
    "\n",
    "for text in vrt.texts:\n",
    "    # This text belongs in this bin\n",
    "    bin_number = month_number(text.date) - min_months\n",
    "    # Increment the counter for that bin\n",
    "    counts[bin_number] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f09252",
   "metadata": {},
   "source": [
    "Then we will use a library called `pyplot` to draw a bar chart. By convention, we have imported it as `plt`.\n",
    "\n",
    "To nicely label the X-axis labels, we will tell `plt.xticks()` where to put them and what to call them. Then we build the chart with `plt.bar()` and finally show it inline with `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of x-coordinates for the bars. We want as many bars as there are entries in daterange.\n",
    "x_ticks = range(len(daterange))\n",
    "\n",
    "# For each x-axis label, show just the year and month\n",
    "x_labels = [f\"{date.year}-{date.month}\" for date in daterange]\n",
    "\n",
    "# Give x_ticks and x_labels to pyplot. rotation = 45 makes the labels tilted so they don't\n",
    "# end up obscuring each other.\n",
    "plt.xticks(ticks = x_ticks, labels = x_labels, rotation = 45)\n",
    "\n",
    "plt.bar(x_ticks, counts) # This is the command to make the bar chart\n",
    "plt.tight_layout() # This adjusts whitespace around the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f15e27",
   "metadata": {},
   "source": [
    "In the above graph, you should be able to use the mouse to interactively investigate it. If you choose the pan tool, you can hold down the left mouse botton to pan around the view, and the right mouse botton while moving the mouse to zoom in and out. You can also resize the graph as desired.\n",
    "\n",
    "In the zoomed-out view, the x-axis labels are hard to read. One way to reduce clutter is to omit some of the labels. For example, you could try changing the `x_labels` -variable like this:\n",
    "\n",
    "`x_labels = [f\"{date.year}-{date.month}\" if date.month in (1,7) else \"\" for date in daterange]`\n",
    "\n",
    "You can read this as \"If the month number is 1 or 7, make a label like `2020-01`. Otherwise, make an empty label (`\"\"`). If you make that change, and re-run the code cell, you will see the x-labels for the other month numbers disappear.\n",
    "\n",
    "If you're using the Eduskunta data, perhaps you can already make an observation about this histogram?\n",
    "\n",
    "Next, we will try out a way to get some summary numeric data about our texts.\n",
    "\n",
    "If you recall our Korp session, we were wondering about \"noun disease\" and the tendency of language users to turn verbs into nouns, and use very generic verbs with them. One coarse method of seeing how much common verbs dominate is to calculate the inequality of the distribution of the counts of the verbs. For this purpose, we will define a function that will take in a list of lemmas, like `[\"tehd채\", \"olla\", \"tehd채\", \"toteuttaa\"]`, and return the Gini inequality of that list. In the case of the list I just mentioned, there are three different lemmas, one of which occurred twice, and two which occurred once.\n",
    "\n",
    "You don't need to understand the function, just consider the input, output, and try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(instances):\n",
    "    # http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    # First we tally up the count of each item in instances\n",
    "    counts = {}\n",
    "    for instance in instances:\n",
    "        counts[instance] = counts.get(instance, 0) + 1\n",
    "    # The list needs to be sorted, so we do that here, and make it into a numpy array\n",
    "    array = np.array(sorted(counts.values()))\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    n = array.shape[0]\n",
    "    # The formula itself\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b21c4a",
   "metadata": {},
   "source": [
    "Let's try the list I mentioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gini([\"tehd채\", \"olla\", \"tehd채\", \"toteuttaa\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5c024",
   "metadata": {},
   "source": [
    "Feel free to try altering the list and seeing how the inequality value changes. Now let's apply this function to the first text in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first text is vrt.texts[0], because zero is the first index in a Python list\n",
    "verb_tokens = [token for token in vrt.texts[0].tokens() if vrt.token_field_is_value(token, \"pos\", \"V\")]\n",
    "verb_lemmas = vrt.map_tokens_to_field(verb_tokens, \"lemma\")\n",
    "print(gini(verb_lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0010e83",
   "metadata": {},
   "source": [
    "We can wrap this process in another function, that will take a VrtText and return the Gini index of its verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_verb_gini_index(vrt, text):\n",
    "    verb_tokens = [token for token in text.tokens() if vrt.token_field_is_value(token, \"pos\", \"V\")]\n",
    "    verb_lemmas = vrt.map_tokens_to_field(verb_tokens, \"lemma\")\n",
    "    return gini(verb_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00f1b7",
   "metadata": {},
   "source": [
    "Now we can get the inequality index of each of the first 10 texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ca772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in vrt.texts[:10]:\n",
    "    print(text_to_verb_gini_index(vrt, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0ea6f",
   "metadata": {},
   "source": [
    "Now we have a number to plot, calculate correlations with, or filter to find interesting texts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
